{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import shutil\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "# Earliest year with municipality-level data\n",
    "BEGIN: str = \"01.01.1945\"\n",
    "# Reserve 2024 for out-of-sample predictions\n",
    "# and, the new maps (starting Sept. 2023) aren't supported by the current code\n",
    "END: str = \"01.07.2023\"\n",
    "# We don't have municipality-level data for these votes.\n",
    "EXCLUDES = [616, 617]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bily/miniforge3/envs/ask-volk-today/lib/python3.12/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "swiss_votes = pd.read_csv(\"../data/raw/swissvotes_dataset.csv\", sep=\";\")\n",
    "mun_reg = pd.read_excel(\n",
    "    \"../data/raw/be-t-00.04-agv-01.xlsx\", sheet_name=\"GDE\"\n",
    ")  # List of municipalities\n",
    "can_reg = pd.read_excel(\n",
    "    \"../data/raw/be-t-00.04-agv-01.xlsx\", sheet_name=\"KT\"\n",
    ")  # List of cantons\n",
    "mun_mut = pd.read_excel(\n",
    "    \"../data/raw/Mutierte_Gemeinden.xlsx\", sheet_name=\"Daten\", header=[0, 1]\n",
    ")  # List of merged municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTAKES_MAP = {\n",
    "    \"Rebévelier (BE)\": \"Rebévelier\",\n",
    "    \"Roggenburg (BE)\": \"Roggenburg\",\n",
    "    \"Neuveville\": \"La Neuveville\",\n",
    "    \"La La Neuveville\": \"La Neuveville\",\n",
    "    \"Maconnens\": \"Massonnens\",\n",
    "    \"Ichterswil\": \"Richterswil\",\n",
    "    \"BBöckten\": \"Böckten\",\n",
    "    \"Oberendingen\": \"Endingen\",\n",
    "    \"Roveredo (TI)\": \"Roveredo-Capriasca\",\n",
    "    \"MMülchi\": \"Mülchi\",\n",
    "    \"DDättwil\": \"Dättwil\",\n",
    "    \"Röthenbach b. Herzogenbuchsee\": \"Röthenbach bei Herzogenbuchsee\",\n",
    "    \"Röthenbach bei Herz'buchsee\": \"Röthenbach bei Herzogenbuchsee\",\n",
    "    \"Castel san Pietro\": \"Castel San Pietro\",\n",
    "    \"Vugelles-la Mothe\": \"Vugelles-La Mothe\",\n",
    "    \"Montet (GlMontet (Glâne)\": \"Montet (Glâne)\",\n",
    "    \"La CLa Côte-aux-Fées\": \"La Côte-aux-Fées\",\n",
    "    \"Le PLe Pâquier (FR)\": \"Le Pâquier (FR)\",\n",
    "    \"MMörel\": \"Mörel\",\n",
    "    \"LLü\": \"Lü\",\n",
    "    \"NorNoréaz\": \"Noréaz\",\n",
    "    \"TrTrüllikon\": \"Trüllikon\",\n",
    "    \"KKüttigkofen\": \"Küttigkofen\",\n",
    "    \"MMézières (VD)\": \"Mézières (VD)\",\n",
    "    \"Büchseln\": \"Büchslen\",\n",
    "    \"Lohn\": \"Lohn (GR)\",\n",
    "    \"Jouxtens-Mezery\": \"Jouxtens-Mézery\",\n",
    "    \"Crans-près-Celigny\": \"Crans-près-Céligny\",\n",
    "    \"Saint-Leonard\": \"Saint-Léonard\",\n",
    "    \"RRümlang\": \"Rümlang\",\n",
    "    \"PrPréverenges\": \"Préverenges\",\n",
    "    \"SSévaz\": \"Sévaz\",\n",
    "    \"EnnetbEnnetbürgen\": \"Ennetbürgen\",\n",
    "    \"RRüdlingen\": \"Rüdlingen\",\n",
    "    \"SSévery\": \"Sévery\",\n",
    "    \"LLüscherz\": \"Lüscherz\",\n",
    "    \"Bois-d’Amont\": \"Bois-d'Amont\",\n",
    "    \"Obersa Mundaun\": \"Obersaxen Mundaun\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Collect vote results on municipality level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwissvotesVotesDatasetBuilder:\n",
    "    _xlsx_columns = [\"region_id\", \"region_name\", \"votes_total\", \"votes_yes\"]\n",
    "    _drop_id_threshold = 19000\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sv_df: pd.DataFrame,\n",
    "        mun_reg: pd.DataFrame,\n",
    "        can_reg: pd.DataFrame,\n",
    "        mun_mut: pd.DataFrame,\n",
    "        begin: str = BEGIN,\n",
    "        end: str = END,\n",
    "        excludes: list[int] = EXCLUDES,\n",
    "        mistakes_map: dict = MISTAKES_MAP,\n",
    "        cache_dir: Path = Path(tempfile.gettempdir()),\n",
    "    ) -> None:\n",
    "        self.sv_df = sv_df\n",
    "        self.mun_reg = mun_reg\n",
    "        self.can_reg = can_reg\n",
    "        self.mun_mut = mun_mut\n",
    "        self.cache_dir = cache_dir\n",
    "        self.mistakes_map = mistakes_map\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.begin = begin\n",
    "        self.end = end\n",
    "        self.excludes = excludes\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_id(url):\n",
    "        if pd.isnull(url):\n",
    "            return None\n",
    "        map_id = url.split(\"/\")[-1]\n",
    "        map_nr = map_id.split(\"_\")[0]\n",
    "        if \"html\" in map_nr:\n",
    "            return None\n",
    "        return map_nr\n",
    "\n",
    "    @staticmethod\n",
    "    def _download_file(url: str, path: Path):\n",
    "        local_filename = path / url.split(\"/\")[-1]\n",
    "        with requests.get(url, stream=True, timeout=5) as r:\n",
    "            with open(local_filename, \"wb\") as f:\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "        return local_filename\n",
    "\n",
    "    @staticmethod\n",
    "    def _combine_xlsx(df: pd.DataFrame):\n",
    "        vote_df = pd.DataFrame(\n",
    "            columns=SwissvotesVotesDatasetBuilder._xlsx_columns + [\"vote_id\"]\n",
    "        )\n",
    "        for _, row in df.iterrows():\n",
    "            local_filename = row[\"local_filename\"]\n",
    "            print(f\"Processing {local_filename}\")\n",
    "            try:\n",
    "                xlsx = pd.read_excel(\n",
    "                    local_filename, names=SwissvotesVotesDatasetBuilder._xlsx_columns\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {local_filename}: {e}\")\n",
    "                continue\n",
    "            xlsx[\"vote_id\"] = row[\"anr\"]\n",
    "            # Drop rows that are not data.\n",
    "            xlsx = xlsx[pd.to_numeric(xlsx[\"region_id\"], errors=\"coerce\").notnull()]\n",
    "            # Convert region_id to numeric.\n",
    "            xlsx[\"region_id\"] = pd.to_numeric(xlsx[\"region_id\"], errors=\"coerce\")\n",
    "            # Drop votes that don't belong to a region.\n",
    "            xlsx = xlsx[\n",
    "                xlsx[\"region_id\"] < SwissvotesVotesDatasetBuilder._drop_id_threshold\n",
    "            ]\n",
    "            vote_df = pd.concat([vote_df, xlsx])\n",
    "        return vote_df\n",
    "\n",
    "    def _harmonize_municipalities(self, df: pd.DataFrame):\n",
    "        df = df.dropna(subset=[\"region_name\"])\n",
    "        # Adjust municipality names to match the ones in the municipality register.\n",
    "        df[\"region_name\"] = df[\"region_name\"].replace(self.mistakes_map)\n",
    "        df[\"region_name\"] = df[\"region_name\"].replace(\n",
    "            mun_mut[(\"Vorgänger\", \"Gemeindename\")].tolist(),\n",
    "            mun_mut[(\"Nachfolger\", \"Gemeindename\")].tolist(),\n",
    "        )\n",
    "\n",
    "        # Map municipality names to municipality IDs.\n",
    "        muni_id_map = self.mun_reg.set_index(\"GDENAME\")[\"GDENR\"]\n",
    "        df[\"region_id\"] = df[\"region_name\"].map(muni_id_map)\n",
    "\n",
    "        # Map municipality IDs to canton IDs.\n",
    "        can_id_map = self.can_reg.set_index(\"GDEKTNA\")[\"KTNR\"]\n",
    "        self.mun_reg[\"KTNR\"] = self.mun_reg[\"GDEKTNA\"].map(can_id_map)\n",
    "        muni_id_can_id_map = self.mun_reg.set_index(\"GDENR\")[\"KTNR\"]\n",
    "        df[\"canton_id\"] = df[\"region_id\"].map(muni_id_can_id_map)\n",
    "        return df\n",
    "        \n",
    "    def build(self):\n",
    "        url_df = self.sv_df[[\"anr\", \"datum\", \"bfsmap-de\"]]\n",
    "        start_date = datetime.strptime(self.begin, \"%d.%m.%Y\")\n",
    "        end_date = datetime.strptime(self.end, \"%d.%m.%Y\")\n",
    "        url_df[\"datum\"] = pd.to_datetime(url_df[\"datum\"], format=\"%d.%m.%Y\")\n",
    "        url_df = url_df[(url_df[\"datum\"] >= start_date) & (url_df[\"datum\"] <= end_date)]\n",
    "        url_df[\"map_nr\"] = url_df[\"bfsmap-de\"].apply(self._extract_id)\n",
    "        url_df[\"xlsx\"] = url_df[\"map_nr\"].apply(\n",
    "            lambda map_nr: f\"https://www.atlas.bfs.admin.ch/core/projects/12/xshared/xlsx/{map_nr}_131.xlsx\"\n",
    "        )\n",
    "        dl_func = functools.partial(self._download_file, path=self.cache_dir)\n",
    "        # url_df[\"local_filename\"] = url_df[\"xlsx\"].apply(dl_func)\n",
    "        # url_df = url_df.dropna(subset=[\"map_nr\"])\n",
    "        url_df[\"local_filename\"] = self.cache_dir / url_df[\"map_nr\"].apply(lambda x: f\"{x}_131.xlsx\")\n",
    "        vote_df = self._combine_xlsx(url_df)\n",
    "        vote_df.to_csv(self.cache_dir / \"votes.csv\", index=False)\n",
    "        vote_df = pd.read_csv(self.cache_dir / \"votes.csv\")\n",
    "        vote_df = self._harmonize_municipalities(vote_df)\n",
    "        vote_df = self._postprocess(vote_df)\n",
    "        self.df = vote_df\n",
    "\n",
    "    def _postprocess(self, df):\n",
    "        df = df.drop_duplicates()\n",
    "        df = df[~df[\"vote_id\"].isin(self.excludes)]\n",
    "        # Keep missing vote results as NaN; handle them later.\n",
    "        df[\"votes_total\"] = df[\"votes_total\"].replace(\"*\", np.nan)\n",
    "        df[\"votes_yes\"] = df[\"votes_yes\"].replace(\"*\", np.nan)\n",
    "        df[\"votes_total\"] = df[\"votes_total\"].astype(float)\n",
    "        df[\"votes_yes\"] = df[\"votes_yes\"].astype(float)\n",
    "        return df\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"Accessor for the dataset.\"\"\"\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SwissvotesVotesDatasetBuilder(\n",
    "    swiss_votes,\n",
    "    mun_reg=mun_reg,\n",
    "    can_reg=can_reg,\n",
    "    mun_mut=mun_mut,\n",
    "    begin=BEGIN,\n",
    "    end=END,\n",
    "    excludes=EXCLUDES,\n",
    "    cache_dir=Path(\"../data/interim/swissvotes\"),\n",
    "    mistakes_map=MISTAKES_MAP,\n",
    ")\n",
    "builder.build()\n",
    "builder.dataset.to_csv(\"../data/processed/swissvotes_votes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Topics / Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwissvotesTopicDatasetBuilder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sv_df: pd.DataFrame,\n",
    "        mun_map: pd.DataFrame,\n",
    "        mun_mut: pd.DataFrame,\n",
    "        begin: str = BEGIN,\n",
    "        end: str = END,\n",
    "        excludes: list[int] = EXCLUDES,\n",
    "        mistakes_map: dict = MISTAKES_MAP,\n",
    "        cache_dir: Path = Path(tempfile.gettempdir()),\n",
    "    ) -> None:\n",
    "        self.sv_df = sv_df\n",
    "        self.mun_map = mun_map\n",
    "        self.mun_mut = mun_mut\n",
    "        self.cache_dir = cache_dir\n",
    "        self.mistakes_map = mistakes_map\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.begin = begin\n",
    "        self.end = end\n",
    "        self.excludes = excludes\n",
    "\n",
    "    @staticmethod\n",
    "    def _transform_topics(df: pd.DataFrame):\n",
    "        tdf = df.replace(\".\", np.nan)\n",
    "        code_cols = []\n",
    "        for i in range(1, 4):\n",
    "            col_1 = f\"d{i}e1\"\n",
    "            col_2 = f\"d{i}e2\"\n",
    "            col_3 = f\"d{i}e3\"\n",
    "            tdf[col_1] = tdf[col_1].fillna(0.0)\n",
    "            tdf[col_2] = tdf[col_2].fillna(tdf[col_1])\n",
    "            tdf[col_3] = tdf[col_3].fillna(tdf[col_2])\n",
    "            code_cols.append((tdf[col_3].astype(float) * 100).astype(int))\n",
    "            tdf.drop([col_1, col_2, col_3], axis=1, inplace=True)\n",
    "\n",
    "        codes = set(np.concatenate([code_col.values for code_col in code_cols]))\n",
    "        codes.remove(0)\n",
    "\n",
    "        topics = [pd.get_dummies(pd.Categorical(code_col, categories=codes)) for code_col in code_cols]\n",
    "        topics = functools.reduce(lambda x, y: x | y, topics)\n",
    "        topics.columns = [f\"topic_{i}\" for i in topics.columns]\n",
    "        tdf.reset_index(inplace=True)\n",
    "        tdf = tdf.join(topics)\n",
    "        tdf.drop(\"index\", axis=1, inplace=True)\n",
    "        return tdf\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        topic_df = self.sv_df[\n",
    "            [\n",
    "                \"anr\",\n",
    "                \"datum\",\n",
    "                \"d1e1\",\n",
    "                \"d1e2\",\n",
    "                \"d1e3\",\n",
    "                \"d2e1\",\n",
    "                \"d2e2\",\n",
    "                \"d2e3\",\n",
    "                \"d3e1\",\n",
    "                \"d3e2\",\n",
    "                \"d3e3\",\n",
    "            ]\n",
    "        ]\n",
    "        start_date = datetime.strptime(self.begin, \"%d.%m.%Y\")\n",
    "        end_date = datetime.strptime(self.end, \"%d.%m.%Y\")\n",
    "        topic_df[\"datum\"] = pd.to_datetime(topic_df[\"datum\"], format=\"%d.%m.%Y\")\n",
    "        topic_df = topic_df[(topic_df[\"datum\"] >= start_date) & (topic_df[\"datum\"] <= end_date)]\n",
    "        topic_df = topic_df[~topic_df[\"anr\"].isin(self.excludes)]\n",
    "        self.topic_df = topic_df\n",
    "        topic_df = self._transform_topics(topic_df)\n",
    "        self.topic_df = topic_df\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"Accessor for the dataset.\"\"\"\n",
    "        return self.topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_998/822626779.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  topic_df[\"datum\"] = pd.to_datetime(topic_df[\"datum\"], format=\"%d.%m.%Y\")\n"
     ]
    }
   ],
   "source": [
    "builder = SwissvotesTopicDatasetBuilder(\n",
    "    swiss_votes,\n",
    "    mun_map=mun_reg,\n",
    "    mun_mut=mun_mut,\n",
    "    begin=BEGIN,\n",
    "    end=END,\n",
    "    excludes=EXCLUDES,\n",
    "    cache_dir=Path(\"../data/interim/swissvotes\"),\n",
    "    mistakes_map=MISTAKES_MAP,\n",
    ")\n",
    "\n",
    "builder.build()\n",
    "builder.dataset.to_csv(\"../data/processed/swissvotes_topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask-volk-today",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
